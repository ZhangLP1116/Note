> 简介
>
> ​		实时音频和实时视频的快速发展大约在2000年，有两个因素促进了这种增长，1、个人计算机变的普及并且大多数计算机都带有视频音频处理硬件，2、Internet带宽的大量扩张。
>
> ​		由于有足够的带宽来承载音频和视频，那么设计音频和视频应用的关键问题就是网络延迟。绝对的网络延迟对其影响不大，当时相对变化的延迟所带来的抖动问题往往是用户无法接受的。抖动必须被播放器掩盖。
>
> ​		本节先介绍数字音频和视频，然后介绍3种应用。

> 数字音频
>
> ## 		**简介**
>
> ​		音频波是一种一维声波，当声波进入耳朵是，鼓膜发生振动，从而引起内耳的微细感骨与之一起震动，并向大脑发生神经脉冲。听者感觉到这种脉冲就是声音。
>
> ​		数字音频是声波的数字表示，这种表示能够重现音频，通过模数转换器（ADC）可以将音频波转换为数字形式。数字音频的拟真度在于对模拟信号的采样频率。采用频率越高音频质量越好，但是有尼奎斯特定理的上限值。相反将数字信号转换为音频波可以通过数模转换器（DAC）。
>
> ## 		**音频压缩**
>
> ​		音频压缩的目的是减少带宽需求和传输时间，音频的实时性的要求较高。所有压缩系统都需要准备两种算法：一种用在远端上压缩数据，一种用在接收方上解压数据。这里将压缩称为编码算法，解压称为解码算法。
>
> ​		**压缩算法的不对称性**非常重要：多数文件都只在源端被编码一次，在接收端被解码无数次。这种特性意味着编码算法较慢而且需要昂贵的硬件是可以接受的，重要解码算法的速度快且不需要昂贵的硬件。(实时多媒体环境下又要求源端的编码速度要快)
>
> ​		压缩的第二个不对称性是**内容的不对称**，压缩算法运行解码后的内容和原本的内容又一些差别，这些差别不影响使用即是可以接受的。这种压缩称为**有损压缩**，而输入和输出内容完全一致的压缩称为**无损压缩**。
>
> ​		**音频压缩原理：**可以通过两种方法实现，1、波形编码，它通过傅里叶变换将信号数学转换成频率分量。2、感知编码，它利用人类听觉系统的某些缺陷来对信号进行编码，感知编码建立在心理声学基础上，即人类是如何听到声音的。
>
> ​		**音频压缩算法：**最流行的音频压缩算法是MP3（MPEG audio layer 3）和AAC（高级音频编码，Advanced Audio Coding），ACC由MP4文件（MPEG-4）给出。MP3和ACC都是基于感知编码实现的算法。感知编码的关键性特点是某些声音可以**屏蔽**，比如在一个嘈杂环境中存在各种声音，而一些细微的声音是无法被听到的，这种情况称为**频率屏蔽**。另一种情况是在一种巨响过后短暂时间内都无法听到其他声音，这种情况称为**暂时屏蔽**。**MP3和AAC本质就是对声音较小傅里叶变换，以便得到每个频率处的概率，然后只传送未被屏蔽的频率。并且用就可能少的位数对它们进行编码。**

> 数字视频
>
> ## **简介**
>
> ​		在Internet中视频的流量往往才是大头，一个24分钟的文件若不进行压缩器大小根据像素位的大小可以从100MB~1GB不等。
>
> ​		视频从其原理上看就是一个图像的序列在加上声音，所有下面将先介绍静止图像的压缩标准，在介绍视频的压缩标准，视频压缩标准是在图像压缩标准之上对其每一帧在进行跨帧的冗余度消除。
>
> ## **JPEG标准**
>
> ​		联合图像专家组（JPEG，Joint Photographic Experts Group）用来压缩连续色调的静止图片。它已经得到广泛的应用（jpg文件）。JPEG由国际标准10918定义，比起单一的算法，它更像一个购物清单。它定义了4种模式，其中一种是有损顺序模式，是下面要介绍的。
>
> ​		JPEG有损顺序编码过程
>
> ​			1、对输入进行块准备
>
> ​			2、离散余弦变换
>
> ​			3、量化
>
> ​			4、区分量化
>
> ​			5、运行行程编码（Z字形扫描，减少重复位表示）
>
> ​			6、静态输出编码
>
> ## **MPEG标准**
>
> ​		运动图像专家组（MPEG，Motion Picture Experts Group），可以压缩音频和视频。
>
> ​		MPEG-1首次发布于1993年，它的目标是产生录像机品质的输出，编码率在1Mbps。
>
> ​		MPEG-2发布于1996年，它的目标是压缩广播品质的视频，编码率在4~8Mbps。
>
> ​		MPEG-4有两种视频格式，第一种发布于1999年，基于对象的编码，允许自然图像和合成图像，以及其他媒体的混合，很容易让程序与电影数据交互。第二种格式发布于2003年，称为H.264或高级视频编码（AVC，Advanced Video Coding），它的目标是编码率为早期相同品质水平的视频编码率的一半。
>
> ​		MPEG压缩利用了电影中的空间冗余和时间冗余，空间冗余是对电影的每一帧进行JPEG压缩，时间冗余是在连续相同的几帧上进行压缩。MPEG和JPEG最大的区别就是对于运动图像的补偿。
>
> ​		MPEG输出包含3中帧
>
> ​			I-帧：帧内包含了压缩的静止图片，分隔依赖流，使得发生传输错误只需要找到下一个I帧即可
>
> ​			P-帧：预测帧是与前一帧的逐块差值
>
> ​			B-帧：双向帧是与前一帧和后一帧的逐块差值

> 流式存储媒体
>
> ​		视频网站往往早已将流媒体存储在文件中，等待用户访问。
>
> ​		**最简单的一个Web播放流媒体的模型**是浏览器通过HTTP请求流媒体，服务器传输流媒体，浏览器将流媒体保存在本地，视频播放器开始播放。这种方式的缺点在于视频必须全部下载完后才能观看。
>
> ![image-20210407113019370](C:\Users\zhang\AppData\Roaming\Typora\typora-user-images\image-20210407113019370.png)
>
> ​		**第二种模型**是，浏览器请求流媒体，服务器返回一个元文件，文件内容可能只有一行ASCII文本，如：rtsp://joes-movie-server/movie-0025.mp4，浏览器将这个元文件交给播放器，播放器读取文件用rtsp协议请求媒体服务器，服务器响应，播放器接受后播放内容。
>
> ![image-20210407113107342](C:\Users\zhang\AppData\Roaming\Typora\typora-user-images\image-20210407113107342.png)
>
> ​		在第二种模型中，播放器需要完成以下4项工作
>
> ​		**1、管理用户界面：**面向用户的使用界面
>
> ​		**2、处理传输错误：**若传输协议基于UDP则应用需要对传输错误进行处理。为了解决网络丢包问题由两种解决方式，1、FEC编码，2、交错编码
>
> ​			1）FEC编码：向前纠错，适用于应用程序级的简单纠错编码。原理是每发送4个数据包就发送一个奇偶校验包，可以根据这个奇偶校验包还原其中一个出错的数据包，若有两个包出错则无法纠错。FEC编码的缺点是增加了25%的带宽需求。（P553）
>
> ​			2）交错编码：传输之前将媒体的顺序混合起来，然后再接收端解开交错的媒体，这样如果一个包发生丢失则损失将会分摊到各各时段，降低丢包带来的影响。交错编码的优势是不需要额外的带宽，但增加了传输延迟需要等一组数据包到达后才能解交错。
>
> ​		**3、解压缩内容：**解压缩的关键点如何解决传输过程中的错误，若不能纠正传输错误如何进行解码。因此编码的过程必须设计成不管丢不丢包都能进行解码。这项需求就是为什么MPEG采用I帧、P帧、B帧的缘故，I帧可以独立其他帧进行编码，以便从任何先前帧的损失中恢复。
>
> ​		**4、消除抖动：**一般的解决方案是使用缓冲区，一般缓存区需要设置高水位和低水位，低水位用于指导缓存到多少时可以开始播放，不会因为播放速度太快而导致缓存耗尽。高水位用于告诉服务器传输的媒体足够多了可以适当的降低传输速度，等缓存降低到低水位时在开始加快速度。

> 流式直播媒体
>
> ​		**流式直播媒体的形式：**1、先录制，然后保存分发，2、边录制边分发
>
> ​		**对于第一种形式：**可以用流式存储媒体的方式处理
>
> ​		**对于第二种形式：**在浏览器端两者没有区别，在发送端需要保证抖动所有需要延迟一段时间保证缓存区有一定的内容后在开始分发。
>
> ​		**流式直播的有效分发手段时通过IP组播形式**，每个要接受媒体流的客户必须加入组，这可以通过IGMP协议实现。由于组播时一对多的服务从本质上只能使用UDP传输，应用层使用RTP协议，为了保证传输可靠性可以使用FEC编码。
>
> ​		**现实中上流式媒体分发使用TCP方式服务器与每一个用户建立连接**，使用TCP最主要的原因是IP组播在Internet上并没有真正部署，一些ISP仅在自己网络的内部进行支持。使用TCP后可以带来可靠的传输服务，并且容易穿过用户的防火墙。
>
> ​		**流式组播模型：**直播源（用户机器）通过网络将本地的视频传输到媒体服务器，媒体服务器与接收直播的用户建立TCP连接传输流媒体。

> 实时会议
>
> ​		实时会议和IP语音，与上述两种流媒体有着很大的区别，实时会议和IP语言要求极低的延迟，否则服务无法使用。这一特性导致传输层要使用UDP协议，并且IP层面可以使用区分服务字段加速实时会议和IP语言的包转发速度进一步减少延迟。
>
> ​		这两种模式缓存仍然是需要的，它的主要作用是用来按时播放媒体样值，缓冲区必须保存的非常小。
>
> ​		实时会议实时语言基于的协议：H.323，SIP
> ​		**H.323：**H.323由ITU于1996年发布了推荐标准，H.323模型如下，模型的关键点在于中央的网关，它将Internet网络和电话网络连接在一起，使得用IP呼叫电话变成可能。在**Internet部分使用H.323协议**发送数据，在**电话网络使用PSTN协议**发送数据。工作流程看（P563）
>
> ![image-20210409140906578](C:\Users\zhang\AppData\Roaming\Typora\typora-user-images\image-20210409140906578.png)
>
> ​		**SIP：**H323是由ITU设计的，Internet团体中的许多人把它看成是一个典型的电信产品，庞大复杂而且不灵活。因此IETF建立了一个委员会专门设计一种更加简单和模块化的方法来实现IP语言。主要成果就是会话发起协议——SIP（Session Initiation Protocol）。与H.323不同的是SIP只是单个模块，他被设计的能很好地与现有internet应用协同工作。例如把电话号码定义成URL，用户只要点击一次连接即可发起一次电话呼叫。**SIP是一个应用层协议可以运行在UDP或TCP之上。**
>
> ​		SIP是一个仿HTTP的基于文本的协议，一方面以ASCII文本形式发送一条消息，消息的第一含包含一个方法名，接下来几行包含一些传递参数的头，很多头来源于MIME以便SIP能与Internet应用协调工作。
>
> （SIP与H.323比较，P567）

